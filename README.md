# CAPYBARA ğŸ¾  
**C**ross-study **A**daptive **P**redictions **Y**ielding **B**ayesian **A**ggregation with **R**ecursive **A**nalysis  

> *Imputing values and their uncertainty using multiple training datasets*

---

## Table of Contents
- [CAPYBARA ğŸ¾](#capybara-)
  - [Table of Contents](#table-of-contents)
  - [1  Why CAPYBARA?](#1--why-capybara)
  - [2 Setup \& Installation](#2-setup--installation)
  - [3 Input file format](#3-input-file-format)
  - [4  Quick-start (five lines)](#4--quick-start-five-lines)
  - [5  Full notebook walk-through](#5--full-notebook-walk-through)
    - [5.1  Pre-processing](#51--pre-processing)
    - [5.2  Feature learning/selection (LaplaceRFM)](#52--feature-learningselection-laplacerfm)
    - [5.3  Feature learning/selection when target virus is completely left out](#53--feature-learningselection-when-target-virus-is-completely-left-out)
    - [5.4  Get predictions and transferability across datasets for each virus, each dataset pair](#54--get-predictions-and-transferability-across-datasets-for-each-virus-each-dataset-pair)
    - [5.5  Bayesian combination \& plots](#55--bayesian-combination--plots)
    - [5.5  Adding your own dataset](#55--adding-your-own-dataset)
    - [5.6  Re-creating all paper figures](#56--re-creating-all-paper-figures)
  - [6  Project layout](#6--project-layout)
  - [7  Advanced configuration](#7--advanced-configuration)

---

## 1  Why CAPYBARA?
Traditional models were trained on one dataset and tested on another, yet we are now approaching the regime where we have **many datasets** for training, some of which are far more informative than others. CAPYBARA provides an efficient, principled way to identify the most informative studies and combine their predictions using:

* Recursive Feature Machines to identify the most predictive feature set
* Ridge regression with error quantification (by predicting left-out data to quantify dataset transferability **Ïƒ<sub>Predict</sub>**)  
* Bayesian inverse-variance weighting to combine predictions from multiple studies  
* Helper functions for the specific context of influenza antibody responses we examine (HAI, fold-error, â€¦)

Although the code was built around influenza HAI titres, **any numeric
endpoint** (neutralisation IC<sub>50</sub>, ELISA OD, â€¦) will work seamlessly â€” just change
`response_col` & `response_transform`.

---
## 2 Setup & Installation

```bash
git clone https://github.com/TalEinav/CAPYBARA.git
cd CAPYBARA

# recommended env
conda create -n capybara python=3.10
conda activate capybara

# core deps + Laplace-RFM from GitHub
pip install -r requirements.txt
````

`requirements.txt` pins:

```
torch==1.13.0
torchvision==0.14.0
hickle==5.0.2
tqdm>=4.64
git+https://github.com/aradha/recursive_feature_machines.git@pip_install
â€¦ # plus NumPy, pandas, scikit-learn, matplotlib, seaborn, statsmodels
```

GPU is optional; CPU is fine for the H3N2 case-study.

---

## 3 Input file format

| Column    | Example value           | Required? | Notes                                   |
| --------- | ----------------------- | --------- | --------------------------------------- |
| `Dataset` | `2021 UGA`              | âœ…         | Study / Cohort ID                       |
| `Subject` | `Subject_001`              | âœ…      | Subject ID                   |
| `Time`    | `Day21`                 | âœ…         | Sample collection time-point              |
| `Virus`   | `H3N2 A/Darwin/9/2021` | âœ…         | Feature column that will become a pivot column       |
| `HAI` \*  | `160`                   | âœ…\*       | Numeric measurement (rename via response_col if itâ€™s not â€œHAIâ€) |

*The name â€œHAIâ€ is historical; you can pass response_col="Neutralization" (or anything else).

---

## 4  Quick-start (five lines)

```python
from capybara.preprocess import DataPreprocessor
from capybara.pipeline   import LaplaceRFMAnalyzer, RidgeTrainer

data = DataPreprocessor(paths=["data/master.csv"]).run()[1]    # dataset_dict
groups, imp   = LaplaceRFMAnalyzer(data).run_analysis()
ridge_res     = RidgeTrainer(groups, imp, data).run()
```

You now have:

* `groups` â€“ chosen feature sets per (dataset, virus)
* `ridge_res` â€“ Ïƒ<sub>Actual</sub>, Ïƒ<sub>Predict</sub>, RÂ², per
  trainâ†’test pair

Jump to the notebook section below for the full publication-grade workflow.

---

## 5  Full notebook walk-through

**File:** `notebooks/CAPYBARA_Full_Pipeline.ipynb`
Run the cells top-to-bottom or use them as templates.

### 5.1  Pre-processing

```python
from capybara.preprocess import DataPreprocessor
pre = DataPreprocessor(
    paths=["Data/Dataset Master File.csv"],
    response_col="HAI",
    response_transform=lambda x: np.log2(x/5),  # default HAI transform
    viruses_to_keep=["H3N2"]                    # OR [] for all viruses
)
filtered_df, dataset_dict, *_ = pre.run()
```

The pre-processor:

1. Merges multiple CSVs
2. Drops duplicate subjects across studies
3. Fixes *Egg-grown* vs *Cell-grown* naming clashes
4. Pivots to `dataset_dict = {dataset â†’ wide DataFrame}`
5. Imputes missing cells with row/column means

### 5.2  Feature learning/selection (LaplaceRFM)

```python
from capybara.pipeline import LaplaceRFMAnalyzer
groups_dict, importance_dict = LaplaceRFMAnalyzer(dataset_dict).run_analysis()
```

Outputs (per dataset):
`target_virus â†’ [selected_viruses]` + per-link importance.

### 5.3  Feature learning/selection when target virus is completely left out
Each dataset pair ran on overlapping viruses

```python
from capybara.pipeline import RFMGroupAnalysis, TransferabilityAnalysis

# â‹ leave-one-overlap-out Laplace-RFM per (train,test) pair
RFMGroupAnalysis(results_dir="results/leave_one_out_RFM").run(dataset_dict)

```
### 5.4  Get predictions and transferability across datasets for each virus, each dataset pair

```python
from capybara.pipeline import TransferabilityAnalysis

# âŒ ÏƒPredict via ODR + upper-bound line
TransferabilityAnalysis().run_transferability_analysis(
    dataset_dict,
    combined_virus_groups_dict_path="results/virus_groups_all_datasets.json",
    loo_folder="results/leave_one_out_RFM/groups",
    performance_folder="results/transferability",
    n_splits=5
)
```

### 5.5  Bayesian combination & plots

```python
from capybara.combining_predictions import (
    DataSetNameParser, TrainTestIndexBuilder, PredictionCombiner, PredictionPlotter
)

idx  = TrainTestIndexBuilder(DataSetNameParser()).build_train_test_index(
          "results/transferability", list(dataset_dict.keys()))
files = PredictionCombiner().filter_files_for_test_and_train(
          idx, test_dataset_name="2017 UGA", chosen_train_datasets=["2016 UGA", "2007-2011 Fonv Infect"])
combined = PredictionCombiner().combine_subset_predictions(files)
PredictionPlotter(jitter_strength=0.05, dot_color="plum").plot_combined_predictions(
          combined, dataset_name="2017 UGA", train_datasets_used=["2016 UGA", "2007-2011 Fonv Infect"])
```

Produces **Fig 2A** in the manuscript.

### 5.5  Adding your own dataset

```python
from capybara.preprocess import DataPreprocessor
from capybara.pipeline   import RFMGroupAnalysis, TransferabilityAnalysis
from capybara.combining_predictions import PredictionCombiner

# read only your cohort:
df_all  = pd.read_csv("Dataset File.csv")
my_ds   = "2024_NewStudy"
df_all[df_all["Dataset"] == my_ds].to_csv("tmp_only.csv", index=False)

# reuse the same pipeline
_, new_dict, *_ = DataPreprocessor(paths=["tmp_only.csv"]).run()
dataset_dict[my_ds] = new_dict[my_ds]

# run leave-one-out RFM only for (train, my_dastaset) pairs that share â‰¥3 viruses
RFMGroupAnalysis("results/leave_one_out_RFM").run(dataset_dict)

TransferabilityAnalysis().run_transferability_analysis(
    dataset_dict,
    "results/virus_groups_all_datasets.json",
    "results/leave_one_out_RFM/groups",
    "results/transferability",
    n_splits=5
)

# combine & plot
idx   = TrainTestIndexBuilder(DataSetNameParser()).build_train_test_index(
          "results/transferability", list(dataset_dict.keys()))
files = PredictionCombiner().filter_files_for_test_and_train(idx, my_ds,
          chosen_train_datasets=[ds for ds in dataset_dict if ds != my_ds])
combined = PredictionCombiner().combine_subset_predictions(files)
PredictionPlotter(dot_color="teal").plot_combined_predictions(
          combined, dataset_name=my_ds, train_datasets_used="all")
```
### 5.6  Re-creating all paper figures

The notebook cells titled **â€œFigure 2â€, â€œFigure 3â€, â€œFigure 4â€, â€œFigure 5â€**
emit PDF/PNG panels into `Figures/Panels/`.
Run them unchanged to reproduce the manuscript.

---

## 6  Project layout

```
CAPYBARA/
â”œâ”€â”€ Capybara/                 # core modules
â”‚   â”œâ”€â”€ __init__.py           # way to load all from pipeline and preprocess quickly
â”‚   â”œâ”€â”€ preprocess.py         # long â†’ wide
â”‚   â”œâ”€â”€ pipeline.py           # RFM, Ridge, transferability, combining predictions
â”‚   â”œâ”€â”€ performance_analyzer.py # graphs to see general reliability of capybara model
â”‚   â”œâ”€â”€ ridge_equations.py    # interpretable linear formulas
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ CAPYBARA_Full_Pipeline.ipynb
â”œâ”€â”€ Data/                     # place raw CSVs here
â”œâ”€â”€ Results/                  # models, JSONs, etc. (auto-generated)
â”œâ”€â”€ Figures/                  # publication figures (auto-generated)
â”œâ”€â”€ requirements.txt          # necessary packages
â””â”€â”€ README.md
```

---

## 7  Advanced configuration

| Parameter            | Where                            | Default                  | Meaning                                                   |
| -------------------- | -------------------------------- | ------------------------ | --------------------------------------------------------- |
| `response_col`       | `DataPreprocessor`               | `"HAI"`                  | Column holding your measurement                           |
| `response_transform` | `DataPreprocessor`               | `lambda x: np.log2(x/5)` | Callable applied **per value**; set `lambda x: x` to skip |
| `viruses_to_keep`    | `DataPreprocessor`               | `[]`                     | Regex listâ€”empty = keep all                               |
| `Config.BANDWIDTH`   | `capybara/config.py`             | `20`                   | Laplace-RFM kernel width                                  |
| `Config.REG`         | idem                             | `1e-6`                   | Ridge/Laplace regularisation                              |
| `min_overlap`        | `RidgeTrainer` / `OverlapFinder` | `3`                      | Minimum shared viruses to compare datasets                |

---
